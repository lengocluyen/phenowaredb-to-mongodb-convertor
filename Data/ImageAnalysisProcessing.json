{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 4,
    "imageAnalysisProcessingname": "Mon1erImgProc2"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "Mon Essai processing 2",
  "processingScript": "\u003cRoot\u003e\r\n\u003cCode\u003e\u003c![CDATA[import cv2\r\nimport sys\r\nimport vp2\r\nimport VpTypes\r\nimport numpy as np\r\n\r\ndef imread(flags):\r\n    \r\n  im \u003d cv2.imread( sys.argv[1], flags )\r\n  return { \u0027image\u0027 : im }\r\n  \r\ndef background(image,background,foreground):\r\n\r\n    #Add back and fore ground\r\n    selection \u003d background.ColorList + foreground.ColorList\r\n    \r\n    if len(selection)\u003c1:\r\n      return\r\n\r\n    #Convert color selection to L*a*b\r\n    sel \u003d cv2.cvtColor( np.array([selection],dtype\u003d\u0027uint8\u0027), cv2.COLOR_BGR2LAB ).astype(\"float32\")[0]\r\n\r\n    #Convert image to L*a*b\r\n    src \u003d cv2.cvtColor( image, cv2.COLOR_BGR2LAB ).astype(\"float32\")\r\n\r\n    #Extract L*a*b image layers\r\n    (l,a,b) \u003d cv2.split( src )\r\n\r\n    #Create image with n depth where n \u003d nb color in selection\r\n    distance \u003d np.zeros( [image.shape[0],image.shape[1],len(selection)] )\r\n\r\n    #for each color in selection calulate color distance with image\r\n    for (i,color) in enumerate(sel):\r\n      distance[:,:,i] \u003d np.square( l - color[0] ) + np.square( a - color[1] ) + np.square( b - color[2] )\r\n\r\n    #find the minimal\r\n    backOrForeground \u003d np.array( [0] * len(background.ColorList) + [255] * len(foreground.ColorList), dtype\u003d\u0027uint8\u0027 )\r\n    label \u003d backOrForeground[ np.argmin( distance, axis\u003d2 ).astype(\u0027uint8\u0027) ]\r\n    \r\n    #Save Binary image\r\n    if len(sys.argv) \u003e 2:\r\n\t\tcv2.imwrite( sys.argv[2], label )\r\n      \r\n    #Result\r\n    leafarea \u003d cv2.countNonZero( label )\r\n    print ( \"leafarea|%d\\t\" % leafarea )\r\n    \r\n    return { \u0027image\u0027 : label }\r\n\r\nvar1 \u003d imread(1)\r\nvar2 \u003d background(var1[\u0027image\u0027],VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(209, 208, 208), (156, 148, 148), (38, 33, 31), (102, 101, 104), (0, 0, 0)]),VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(55, 98, 79), (48, 63, 53)]))]]\u003e\r\n\u003c/Code\u003e\r\n\u003c/Root\u003e\r\n"
}
{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 3,
    "imageAnalysisProcessingname": "Mon1erImgProc"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "Mon Essai processing",
  "processingScript": "\u003cRoot\u003e\r\n\u003cCode\u003e\u003c![CDATA[import cv2\r\nimport sys\r\nimport vp2\r\nimport VpTypes\r\nimport numpy as np\r\n\r\ndef imread(flags):\r\n    \r\n  im \u003d cv2.imread( sys.argv[1], flags )\r\n  return { \u0027image\u0027 : im }\r\n  \r\ndef background(image,background,foreground):\r\n\r\n    #Add back and fore ground\r\n    selection \u003d background.ColorList + foreground.ColorList\r\n    \r\n    if len(selection)\u003c1:\r\n      return\r\n\r\n    #Convert color selection to L*a*b\r\n    sel \u003d cv2.cvtColor( np.array([selection],dtype\u003d\u0027uint8\u0027), cv2.COLOR_BGR2LAB ).astype(\"float32\")[0]\r\n\r\n    #Convert image to L*a*b\r\n    src \u003d cv2.cvtColor( image, cv2.COLOR_BGR2LAB ).astype(\"float32\")\r\n\r\n    #Extract L*a*b image layers\r\n    (l,a,b) \u003d cv2.split( src )\r\n\r\n    #Create image with n depth where n \u003d nb color in selection\r\n    distance \u003d np.zeros( [image.shape[0],image.shape[1],len(selection)] )\r\n\r\n    #for each color in selection calulate color distance with image\r\n    for (i,color) in enumerate(sel):\r\n      distance[:,:,i] \u003d np.square( l - color[0] ) + np.square( a - color[1] ) + np.square( b - color[2] )\r\n\r\n    #find the minimal\r\n    backOrForeground \u003d np.array( [0] * len(background.ColorList) + [255] * len(foreground.ColorList), dtype\u003d\u0027uint8\u0027 )\r\n    label \u003d backOrForeground[ np.argmin( distance, axis\u003d2 ).astype(\u0027uint8\u0027) ]\r\n    \r\n    #Save Binary image\r\n    if len(sys.argv) \u003e 2:\r\n\t\tcv2.imwrite( sys.argv[2], label )\r\n      \r\n    #Result\r\n    leafarea \u003d cv2.countNonZero( label )\r\n    print ( \"leafarea|%d\\t\" % leafarea )\r\n    \r\n    return { \u0027image\u0027 : label }\r\n\r\nvar1 \u003d imread(1)\r\nvar2 \u003d background(var1[\u0027image\u0027],VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(209, 208, 208), (156, 148, 148), (38, 33, 31), (102, 101, 104), (0, 0, 0)]),VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(55, 98, 79), (48, 63, 53)]))]]\u003e\r\n\u003c/Code\u003e\r\n\u003c/Root\u003e\r\n"
}
{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 7,
    "imageAnalysisProcessingname": "Background"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "Background",
  "processingScript": "\u003cFlowView\u003e\r\n  \u003cNode id\u003d\"54172779\" name\u003d\"NodeOpenCV.imread\" x\u003d\"100\" y\u003d\"42\"\u003e\r\n    \u003cflags value\u003d\"1\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"65303132\" name\u003d\"NodeOpenCV.background\" x\u003d\"366\" y\u003d\"41\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"54172779\" /\u003e\r\n    \u003cbackground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107)])\" /\u003e\r\n    \u003cforeground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (38, 50, 43), (24, 68, 54)])\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"10497067\" name\u003d\"NodeOpenCV.morphology\" x\u003d\"605\" y\u003d\"64\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"65303132\" /\u003e\r\n    \u003coperation value\u003d\"open\" /\u003e\r\n    \u003csize value\u003d\"3\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"61327774\" name\u003d\"NodeOpenCV.standardResult\" x\u003d\"802\" y\u003d\"107\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"10497067\" /\u003e\r\n    \u003cscale value\u003d\"(0.0, 0.0, \u0027\u0027)\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cCode\u003eimport cv2\nimport sys\nimport vp\nimport vp2\nimport VpTypes\nimport numpy as np\nimport math\ndef imread(flags):\n\r\n    vp.debug( repr( sys.argv ) )\r\n    im \u003d cv2.imread( sys.argv[1], flags )\r\n    return { \u0027image\u0027 : im }\r\n  \ndef background(image,background,foreground):\n\r\n    #Add back and fore ground\r\n    selection \u003d background.ColorList + foreground.ColorList\r\n    \r\n    if len(selection)\u0026lt;1:\r\n      return\r\n\r\n    #Convert color selection to L*a*b\r\n    sel \u003d cv2.cvtColor( np.array([selection],dtype\u003d\u0027uint8\u0027), cv2.COLOR_BGR2LAB ).astype(\"float32\")[0]\r\n\r\n    #Convert image to L*a*b\r\n    src \u003d cv2.cvtColor( image, cv2.COLOR_BGR2LAB )\r\n\r\n\t  #find index of near euclidian distance to each color pixel    \r\n    weights \u003d np.ones( len(sel), dtype\u003d\u0027float\u0027 )\r\n    #weights \u003d np.array( [1.0]*len(background.ColorList)+[2.0]*len(foreground.ColorList), dtype\u003d\u0027float\u0027 )\r\n    ( results, dst ) \u003d vp2.colorClassification( src, sel.tolist(), weights )\r\n\r\n    #find the minimal\r\n    backOrForeground \u003d np.array( [0] * len(background.ColorList) + [255] * len(foreground.ColorList), dtype\u003d\u0027uint8\u0027 )\r\n    label \u003d backOrForeground[ dst ]\r\n        \r\n    return { \u0027image\u0027 : label }\r\n    \ndef morphology(image,operation,size):\n\r\n    kernel \u003d cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(size,size))  \r\n    im \u003d cv2.morphologyEx( image, operation, kernel )\r\n    return { \u0027image\u0027 : im }\r\n  \ndef standardResult(image,scale):\n    \r\n    if ( len(image.shape) \u0026gt; 2 ):\r\n      raise Exception(\u0027Input image must be monochrom\u0027)\r\n            \r\n    contours,hierarchy \u003d cv2.findContours( np.copy(image), cv2.cv.CV_RETR_EXTERNAL, cv2.cv.CV_CHAIN_APPROX_SIMPLE )\r\n      \r\n    if ( len(contours)\u0026lt;1 ):\r\n      return { \u0027image\u0027 : image }          \r\n    \r\n    #Merge Contours\r\n    concat_contours \u003d contours[0]\r\n    for cnt in contours[1:]:\r\n\t    concat_contours \u003d np.concatenate( [concat_contours, cnt] )\r\n        \r\n    pb_x,pb_y,pb_w,pb_h \u003d cv2.boundingRect(concat_contours)\r\n    \r\n    rect \u003d cv2.minAreaRect( concat_contours )\r\n    (np_x,np_y),(np_w,np_h),np_teta \u003d rect\r\n    \r\n    center_x, center_y, leafarea \u003d vp2.centerOfGravity(image)\r\n    \r\n    (mec_x,mec_y),mec_radius \u003d cv2.minEnclosingCircle(concat_contours)\r\n    \r\n    ellipse \u003d ((-1,-1),(-1,-1),-1)\r\n    if len(concat_contours)\u0026gt;5:\r\n      ellipse \u003d cv2.fitEllipse(concat_contours)\r\n    (ell_x,ell_y),(ell_w,ell_h),ell_teta \u003d ellipse\r\n    \r\n    hull \u003d cv2.convexHull(concat_contours)\r\n    \r\n    #Save binary image    \r\n    if vp.is_script():\r\n      cv2.imwrite( sys.argv[2], image )\r\n    \r\n    #Results generate\r\n    results \u003d { \r\n      \u0027xscale\u0027 : scale[0],\r\n      \u0027yscale\u0027 : scale[1],\r\n      \u0027unitscale\u0027 : scale[2],\r\n      \r\n      \u0027parallelboundingbox_x\u0027 : pb_x,\r\n      \u0027parallelboundingbox_y\u0027 : pb_y,\r\n      \u0027parallelboundingbox_width\u0027 : pb_w,\r\n      \u0027parallelboundingbox_height\u0027 : pb_h,\r\n      \u0027parallelboundingbox_area\u0027 : pb_w*pb_h,\r\n      \r\n      \u0027nonparallelboundingbox_x\u0027 : np_x,\r\n      \u0027nonparallelboundingbox_y\u0027 : np_y,\r\n      \u0027nonparallelboundingbox_width\u0027 : np_w,\r\n      \u0027nonparallelboundingbox_height\u0027 : np_h,\r\n      \u0027nonparallelboundingbox_area\u0027 : np_w*np_h,\r\n      \u0027nonparallelboundingbox_teta\u0027 : np_teta,\r\n      \r\n      \u0027height\u0027 : 0,\r\n      \r\n      \u0027centerofmassx\u0027 : center_x,\r\n      \u0027centerofmassy\u0027 : center_y,\r\n      \r\n      \u0027area_color_1\u0027 : leafarea,\r\n      \u0027area_color_2\u0027 : 0,\r\n      \r\n      \u0027fitellipse_x\u0027 : ell_x,\r\n      \u0027fitellipse_y\u0027 : ell_y,\r\n      \u0027fitellipse_width\u0027 : ell_w,\r\n      \u0027fitellipse_height\u0027 : ell_h,\r\n      \u0027fitellipse_teta\u0027 : ell_teta,\r\n      \u0027fitellipse_area\u0027 : ( math.pi * ell_w * ell_h ) / 4.,\r\n      \r\n      \u0027minenclosingcircle_x\u0027 : mec_x,\r\n      \u0027minenclosingcircle_y\u0027 : mec_y,\r\n      \u0027minenclosingcircle_radius\u0027 : mec_radius,\r\n      \u0027minenclosingcircle_area\u0027 : math.pi * mec_radius * mec_radius,\r\n      \r\n      \u0027convexhull\u0027 : hull.tolist(),      \r\n      \r\n      }\r\n      \r\n    #Results\r\n    sys.stdout.write ( \u0027\\t\u0027.join([ \"%s|\" % k + str(v) for k,v in results.iteritems() ]) )      \r\n      \r\n    #Draw\r\n    im_rgb \u003d None\r\n    if not vp.is_script():\r\n      im_rgb \u003d cv2.cvtColor( image, cv2.COLOR_GRAY2BGR )\r\n    \r\n      #Center Of gravity\r\n      cog_size \u003d 2\r\n      cv2.line( im_rgb, ( int(center_x) - cog_size, int(center_y) - cog_size ), ( int(center_x) + cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n      cv2.line( im_rgb, ( int(center_x) + cog_size, int(center_y) - cog_size ), ( int(center_x) - cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n    \r\n      #hori rect\r\n      cv2.rectangle(im_rgb,(pb_x,pb_y),(pb_x+pb_w,pb_y+pb_h),(255,0,0))\r\n      #rotate rect\r\n      box \u003d cv2.cv.BoxPoints(rect)\r\n      box \u003d np.int0(box)\r\n      cv2.drawContours(im_rgb,[box],0,(0,0,255))\r\n    \r\n      #Hull\r\n      hull \u003d cv2.convexHull(concat_contours)\r\n      cv2.drawContours(im_rgb,[hull],0,(0,255,0))\r\n    \r\n      #minEnclosingCircle\r\n      center \u003d (int(mec_x),int(mec_y))\r\n      radius \u003d int(mec_radius)\r\n      cv2.circle(im_rgb,center,radius,(0,255,255))\r\n      \r\n      #fitEllipse\r\n      cv2.ellipse(im_rgb,ellipse,(255,0,255))   \r\n    \r\n    return { \u0027image\u0027 : im_rgb }          \r\n\nvar_imread_1 \u003d imread(1)\nvar_background_2 \u003d background(var_imread_1[\u0027image\u0027],VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107)]),VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (38, 50, 43), (24, 68, 54)]))\nvar_morphology_3 \u003d morphology(var_background_2[\u0027image\u0027],2L,3)\nvar_standardResult_4 \u003d standardResult(var_morphology_3[\u0027image\u0027],(0.0, 0.0, \u0027\u0027))\n\u003c/Code\u003e\r\n\u003c/FlowView\u003e"
}
{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 8,
    "imageAnalysisProcessingname": "Background"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "Background",
  "processingScript": "\u003cFlowView\u003e\r\n  \u003cNode id\u003d\"54172779\" name\u003d\"NodeOpenCV.imread\" x\u003d\"100\" y\u003d\"42\"\u003e\r\n    \u003cflags value\u003d\"1\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"65303132\" name\u003d\"NodeOpenCV.background\" x\u003d\"366\" y\u003d\"41\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"54172779\" /\u003e\r\n    \u003cbackground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107)])\" /\u003e\r\n    \u003cforeground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (38, 50, 43), (24, 68, 54)])\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"10497067\" name\u003d\"NodeOpenCV.morphology\" x\u003d\"605\" y\u003d\"64\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"65303132\" /\u003e\r\n    \u003coperation value\u003d\"open\" /\u003e\r\n    \u003csize value\u003d\"3\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"61327774\" name\u003d\"NodeOpenCV.standardResult\" x\u003d\"802\" y\u003d\"107\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"10497067\" /\u003e\r\n    \u003cscale value\u003d\"(0.0, 0.0, \u0027\u0027)\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cCode\u003eimport cv2\nimport sys\nimport vp\nimport vp2\nimport VpTypes\nimport numpy as np\nimport math\ndef imread(flags):\n\r\n    vp.debug( repr( sys.argv ) )\r\n    im \u003d cv2.imread( sys.argv[1], flags )\r\n    return { \u0027image\u0027 : im }\r\n  \ndef background(image,background,foreground):\n\r\n    #Add back and fore ground\r\n    selection \u003d background.ColorList + foreground.ColorList\r\n    \r\n    if len(selection)\u0026lt;1:\r\n      return\r\n\r\n    #Convert color selection to L*a*b\r\n    sel \u003d cv2.cvtColor( np.array([selection],dtype\u003d\u0027uint8\u0027), cv2.COLOR_BGR2LAB ).astype(\"float32\")[0]\r\n\r\n    #Convert image to L*a*b\r\n    src \u003d cv2.cvtColor( image, cv2.COLOR_BGR2LAB )\r\n\r\n\t  #find index of near euclidian distance to each color pixel    \r\n    weights \u003d np.ones( len(sel), dtype\u003d\u0027float\u0027 )\r\n    #weights \u003d np.array( [1.0]*len(background.ColorList)+[2.0]*len(foreground.ColorList), dtype\u003d\u0027float\u0027 )\r\n    ( results, dst ) \u003d vp2.colorClassification( src, sel.tolist(), weights )\r\n\r\n    #find the minimal\r\n    backOrForeground \u003d np.array( [0] * len(background.ColorList) + [255] * len(foreground.ColorList), dtype\u003d\u0027uint8\u0027 )\r\n    label \u003d backOrForeground[ dst ]\r\n        \r\n    return { \u0027image\u0027 : label }\r\n    \ndef morphology(image,operation,size):\n\r\n    kernel \u003d cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(size,size))  \r\n    im \u003d cv2.morphologyEx( image, operation, kernel )\r\n    return { \u0027image\u0027 : im }\r\n  \ndef standardResult(image,scale):\n    \r\n    if ( len(image.shape) \u0026gt; 2 ):\r\n      raise Exception(\u0027Input image must be monochrom\u0027)\r\n            \r\n    contours,hierarchy \u003d cv2.findContours( np.copy(image), cv2.cv.CV_RETR_EXTERNAL, cv2.cv.CV_CHAIN_APPROX_SIMPLE )\r\n      \r\n    if ( len(contours)\u0026lt;1 ):\r\n      return { \u0027image\u0027 : image }          \r\n    \r\n    #Merge Contours\r\n    concat_contours \u003d contours[0]\r\n    for cnt in contours[1:]:\r\n\t    concat_contours \u003d np.concatenate( [concat_contours, cnt] )\r\n        \r\n    pb_x,pb_y,pb_w,pb_h \u003d cv2.boundingRect(concat_contours)\r\n    \r\n    rect \u003d cv2.minAreaRect( concat_contours )\r\n    (np_x,np_y),(np_w,np_h),np_teta \u003d rect\r\n    \r\n    center_x, center_y, leafarea \u003d vp2.centerOfGravity(image)\r\n    \r\n    (mec_x,mec_y),mec_radius \u003d cv2.minEnclosingCircle(concat_contours)\r\n    \r\n    ellipse \u003d ((-1,-1),(-1,-1),-1)\r\n    if len(concat_contours)\u0026gt;5:\r\n      ellipse \u003d cv2.fitEllipse(concat_contours)\r\n    (ell_x,ell_y),(ell_w,ell_h),ell_teta \u003d ellipse\r\n    \r\n    hull \u003d cv2.convexHull(concat_contours)\r\n    \r\n    #Save binary image    \r\n    if vp.is_script():\r\n      cv2.imwrite( sys.argv[2], image )\r\n    \r\n    #Results generate\r\n    results \u003d { \r\n      \u0027xscale\u0027 : scale[0],\r\n      \u0027yscale\u0027 : scale[1],\r\n      \u0027unitscale\u0027 : scale[2],\r\n      \r\n      \u0027parallelboundingbox_x\u0027 : pb_x,\r\n      \u0027parallelboundingbox_y\u0027 : pb_y,\r\n      \u0027parallelboundingbox_width\u0027 : pb_w,\r\n      \u0027parallelboundingbox_height\u0027 : pb_h,\r\n      \u0027parallelboundingbox_area\u0027 : pb_w*pb_h,\r\n      \r\n      \u0027nonparallelboundingbox_x\u0027 : np_x,\r\n      \u0027nonparallelboundingbox_y\u0027 : np_y,\r\n      \u0027nonparallelboundingbox_width\u0027 : np_w,\r\n      \u0027nonparallelboundingbox_height\u0027 : np_h,\r\n      \u0027nonparallelboundingbox_area\u0027 : np_w*np_h,\r\n      \u0027nonparallelboundingbox_teta\u0027 : np_teta,\r\n      \r\n      \u0027height\u0027 : 0,\r\n      \r\n      \u0027centerofmassx\u0027 : center_x,\r\n      \u0027centerofmassy\u0027 : center_y,\r\n      \r\n      \u0027area_color_1\u0027 : leafarea,\r\n      \u0027area_color_2\u0027 : 0,\r\n      \r\n      \u0027fitellipse_x\u0027 : ell_x,\r\n      \u0027fitellipse_y\u0027 : ell_y,\r\n      \u0027fitellipse_width\u0027 : ell_w,\r\n      \u0027fitellipse_height\u0027 : ell_h,\r\n      \u0027fitellipse_teta\u0027 : ell_teta,\r\n      \u0027fitellipse_area\u0027 : ( math.pi * ell_w * ell_h ) / 4.,\r\n      \r\n      \u0027minenclosingcircle_x\u0027 : mec_x,\r\n      \u0027minenclosingcircle_y\u0027 : mec_y,\r\n      \u0027minenclosingcircle_radius\u0027 : mec_radius,\r\n      \u0027minenclosingcircle_area\u0027 : math.pi * mec_radius * mec_radius,\r\n      \r\n      \u0027convexhull\u0027 : hull.tolist(),      \r\n      \r\n      }\r\n      \r\n    #Results\r\n    sys.stdout.write ( \u0027\\t\u0027.join([ \"%s|\" % k + str(v) for k,v in results.iteritems() ]) )      \r\n      \r\n    #Draw\r\n    im_rgb \u003d None\r\n    if not vp.is_script():\r\n      im_rgb \u003d cv2.cvtColor( image, cv2.COLOR_GRAY2BGR )\r\n    \r\n      #Center Of gravity\r\n      cog_size \u003d 2\r\n      cv2.line( im_rgb, ( int(center_x) - cog_size, int(center_y) - cog_size ), ( int(center_x) + cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n      cv2.line( im_rgb, ( int(center_x) + cog_size, int(center_y) - cog_size ), ( int(center_x) - cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n    \r\n      #hori rect\r\n      cv2.rectangle(im_rgb,(pb_x,pb_y),(pb_x+pb_w,pb_y+pb_h),(255,0,0))\r\n      #rotate rect\r\n      box \u003d cv2.cv.BoxPoints(rect)\r\n      box \u003d np.int0(box)\r\n      cv2.drawContours(im_rgb,[box],0,(0,0,255))\r\n    \r\n      #Hull\r\n      hull \u003d cv2.convexHull(concat_contours)\r\n      cv2.drawContours(im_rgb,[hull],0,(0,255,0))\r\n    \r\n      #minEnclosingCircle\r\n      center \u003d (int(mec_x),int(mec_y))\r\n      radius \u003d int(mec_radius)\r\n      cv2.circle(im_rgb,center,radius,(0,255,255))\r\n      \r\n      #fitEllipse\r\n      cv2.ellipse(im_rgb,ellipse,(255,0,255))   \r\n    \r\n    return { \u0027image\u0027 : im_rgb }          \r\n\nvar_imread_1 \u003d imread(1)\nvar_background_2 \u003d background(var_imread_1[\u0027image\u0027],VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107)]),VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (38, 50, 43), (24, 68, 54)]))\nvar_morphology_3 \u003d morphology(var_background_2[\u0027image\u0027],2L,3)\nvar_standardResult_4 \u003d standardResult(var_morphology_3[\u0027image\u0027],(0.0, 0.0, \u0027\u0027))\n\u003c/Code\u003e\r\n\u003c/FlowView\u003e"
}
{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 5,
    "imageAnalysisProcessingname": "Mon1erImgProc3"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "Mon Essai processing 3",
  "processingScript": "\u003cRoot\u003e\r\n\u003cCode\u003e\u003c![CDATA[import cv2\r\nimport sys\r\nimport vp2\r\nimport VpTypes\r\nimport numpy as np\r\n\r\ndef imread(flags):\r\n    \r\n  im \u003d cv2.imread( sys.argv[1], flags )\r\n  return { \u0027image\u0027 : im }\r\n  \r\ndef background(image,background,foreground):\r\n\r\n    #Add back and fore ground\r\n    selection \u003d background.ColorList + foreground.ColorList\r\n    \r\n    if len(selection)\u003c1:\r\n      return\r\n\r\n    #Convert color selection to L*a*b\r\n    sel \u003d cv2.cvtColor( np.array([selection],dtype\u003d\u0027uint8\u0027), cv2.COLOR_BGR2LAB ).astype(\"float32\")[0]\r\n\r\n    #Convert image to L*a*b\r\n    src \u003d cv2.cvtColor( image, cv2.COLOR_BGR2LAB ).astype(\"float32\")\r\n\r\n    #Extract L*a*b image layers\r\n    (l,a,b) \u003d cv2.split( src )\r\n\r\n    #Create image with n depth where n \u003d nb color in selection\r\n    distance \u003d np.zeros( [image.shape[0],image.shape[1],len(selection)] )\r\n\r\n    #for each color in selection calulate color distance with image\r\n    for (i,color) in enumerate(sel):\r\n      distance[:,:,i] \u003d np.square( l - color[0] ) + np.square( a - color[1] ) + np.square( b - color[2] )\r\n\r\n    #find the minimal\r\n    backOrForeground \u003d np.array( [0] * len(background.ColorList) + [255] * len(foreground.ColorList), dtype\u003d\u0027uint8\u0027 )\r\n    label \u003d backOrForeground[ np.argmin( distance, axis\u003d2 ).astype(\u0027uint8\u0027) ]\r\n    \r\n    #Save Binary image\r\n    if len(sys.argv) \u003e 2:\r\n\t\tcv2.imwrite( sys.argv[2], label )\r\n      \r\n    #Result\r\n    leafarea \u003d cv2.countNonZero( label )\r\n    print ( \"leafarea|%d\\t\" % leafarea )\r\n    \r\n    return { \u0027image\u0027 : label }\r\n\r\nvar1 \u003d imread(1)\r\nvar2 \u003d background(var1[\u0027image\u0027],VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(209, 208, 208), (156, 148, 148), (38, 33, 31), (102, 101, 104), (0, 0, 0)]),VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(55, 98, 79), (48, 63, 53)]))]]\u003e\r\n\u003c/Code\u003e\r\n\u003c/Root\u003e\r\n"
}
{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 9,
    "imageAnalysisProcessingname": "stdResult"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "",
  "processingScript": "\u003cFlowView\u003e\r\n  \u003cNode id\u003d\"54172779\" name\u003d\"NodeOpenCV.imread\" x\u003d\"61\" y\u003d\"159\"\u003e\r\n    \u003cflags value\u003d\"1\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"41253532\" name\u003d\"NodeOpenCV.standardResult\" x\u003d\"714\" y\u003d\"152\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"8557861\" /\u003e\r\n    \u003cscale value\u003d\"(0.0, 0.0, \u0027m\u0027)\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"23909939\" name\u003d\"NodeOpenCV.imageReference\" x\u003d\"245\" y\u003d\"153\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"54172779\" /\u003e\r\n    \u003cflags value\u003d\"1\" /\u003e\r\n    \u003cthreshold_value value\u003d\"50\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"8557861\" name\u003d\"NodeOpenCV.cvtColor\" x\u003d\"458\" y\u003d\"154\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"23909939\" /\u003e\r\n    \u003ccolor_space_conversion value\u003d\"BGR2GRAY\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cCode\u003eimport cv2\nimport sys\nimport vp\nimport vp2\nimport math\nimport numpy as np\ndef imread(flags):\n\r\n    vp.debug( repr( sys.argv ) )\r\n    im \u003d cv2.imread( sys.argv[1], flags )\r\n    return { \u0027image\u0027 : im }\r\n  \ndef imageReference(image,flags,threshold_value):\n\r\n    vp.debug( repr( sys.argv ) )\r\n    #Read image reference in grayscale\r\n    im_ref \u003d cv2.imread( sys.argv[3], cv2.IMREAD_GRAYSCALE )\r\n    #Convert input image into grayscale\r\n    im_gray \u003d cv2.cvtColor( image, cv2.COLOR_BGR2GRAY )\r\n    #Make image difference \r\n    im_diff \u003d cv2.absdiff(im_gray,im_ref)\r\n    #Apply threshold\r\n    ret, im_thres \u003d cv2.threshold( im_diff, threshold_value, 255, cv2.THRESH_BINARY )\r\n    #Apply mask\r\n    im_final \u003d cv2.bitwise_and(image,image,mask \u003d im_thres)\r\n    return { \u0027image\u0027 : im_final }\r\n    \ndef cvtColor(image,color_space_conversion):\n\r\n    im \u003d cv2.cvtColor( image, color_space_conversion )\r\n    return { \u0027image\u0027 : im }\r\n  \ndef standardResult(image,scale):\n    \r\n    if ( len(image.shape) \u0026gt; 2 ):\r\n      raise Exception(\u0027Input image must be monochrom\u0027)\r\n            \r\n    contours,hierarchy \u003d cv2.findContours( np.copy(image), cv2.cv.CV_RETR_EXTERNAL, cv2.cv.CV_CHAIN_APPROX_SIMPLE )\r\n      \r\n    if ( len(contours)\u0026lt;1 ):\r\n      return { \u0027image\u0027 : image }          \r\n    \r\n    #Merge Contours\r\n    concat_contours \u003d contours[0]\r\n    for cnt in contours[1:]:\r\n\t    concat_contours \u003d np.concatenate( [concat_contours, cnt] )\r\n        \r\n    pb_x,pb_y,pb_w,pb_h \u003d cv2.boundingRect(concat_contours)\r\n    \r\n    rect \u003d cv2.minAreaRect( concat_contours )\r\n    (np_x,np_y),(np_w,np_h),np_teta \u003d rect\r\n    \r\n    center_x, center_y, leafarea \u003d vp2.centerOfGravity(image)\r\n    \r\n    (mec_x,mec_y),mec_radius \u003d cv2.minEnclosingCircle(concat_contours)\r\n    \r\n    ellipse \u003d ((-1,-1),(-1,-1),-1)\r\n    if len(concat_contours)\u0026gt;5:\r\n      ellipse \u003d cv2.fitEllipse(concat_contours)\r\n    (ell_x,ell_y),(ell_w,ell_h),ell_teta \u003d ellipse\r\n    \r\n    hull \u003d cv2.convexHull(concat_contours)\r\n    \r\n    #Save binary image    \r\n    if vp.is_script():\r\n      cv2.imwrite( sys.argv[2], image )\r\n    \r\n    #Results generate\r\n    results \u003d { \r\n      \u0027xscale\u0027 : scale[0],\r\n      \u0027yscale\u0027 : scale[1],\r\n      \u0027unitscale\u0027 : scale[2],\r\n      \r\n      \u0027parallelboundingbox_x\u0027 : pb_x,\r\n      \u0027parallelboundingbox_y\u0027 : pb_y,\r\n      \u0027parallelboundingbox_width\u0027 : pb_w,\r\n      \u0027parallelboundingbox_height\u0027 : pb_h,\r\n      \u0027parallelboundingbox_area\u0027 : pb_w*pb_h,\r\n      \r\n      \u0027nonparallelboundingbox_x\u0027 : np_x,\r\n      \u0027nonparallelboundingbox_y\u0027 : np_y,\r\n      \u0027nonparallelboundingbox_width\u0027 : np_w,\r\n      \u0027nonparallelboundingbox_height\u0027 : np_h,\r\n      \u0027nonparallelboundingbox_area\u0027 : np_w*np_h,\r\n      \u0027nonparallelboundingbox_teta\u0027 : np_teta,\r\n      \r\n      \u0027height\u0027 : 0,\r\n      \r\n      \u0027centerofmassx\u0027 : center_x,\r\n      \u0027centerofmassy\u0027 : center_y,\r\n      \r\n      \u0027area_color_1\u0027 : leafarea,\r\n      \u0027area_color_2\u0027 : 0,\r\n      \r\n      \u0027fitellipse_x\u0027 : ell_x,\r\n      \u0027fitellipse_y\u0027 : ell_y,\r\n      \u0027fitellipse_width\u0027 : ell_w,\r\n      \u0027fitellipse_height\u0027 : ell_h,\r\n      \u0027fitellipse_teta\u0027 : ell_teta,\r\n      \u0027fitellipse_area\u0027 : ( math.pi * ell_w * ell_h ) / 4.,\r\n      \r\n      \u0027minenclosingcircle_x\u0027 : mec_x,\r\n      \u0027minenclosingcircle_y\u0027 : mec_y,\r\n      \u0027minenclosingcircle_radius\u0027 : mec_radius,\r\n      \u0027minenclosingcircle_area\u0027 : math.pi * mec_radius * mec_radius,\r\n      \r\n      \u0027convexhull\u0027 : hull.tolist(),      \r\n      \r\n      }\r\n      \r\n    #Results\r\n    sys.stdout.write ( \u0027\\t\u0027.join([ \"%s|\" % k + str(v) for k,v in results.iteritems() ]) )      \r\n      \r\n    #Draw\r\n    im_rgb \u003d None\r\n    if not vp.is_script():\r\n      im_rgb \u003d cv2.cvtColor( image, cv2.COLOR_GRAY2BGR )\r\n    \r\n      #Center Of gravity\r\n      cog_size \u003d 2\r\n      cv2.line( im_rgb, ( int(center_x) - cog_size, int(center_y) - cog_size ), ( int(center_x) + cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n      cv2.line( im_rgb, ( int(center_x) + cog_size, int(center_y) - cog_size ), ( int(center_x) - cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n    \r\n      #hori rect\r\n      cv2.rectangle(im_rgb,(pb_x,pb_y),(pb_x+pb_w,pb_y+pb_h),(255,0,0))\r\n      #rotate rect\r\n      box \u003d cv2.cv.BoxPoints(rect)\r\n      box \u003d np.int0(box)\r\n      cv2.drawContours(im_rgb,[box],0,(0,0,255))\r\n    \r\n      #Hull\r\n      hull \u003d cv2.convexHull(concat_contours)\r\n      cv2.drawContours(im_rgb,[hull],0,(0,255,0))\r\n    \r\n      #minEnclosingCircle\r\n      center \u003d (int(mec_x),int(mec_y))\r\n      radius \u003d int(mec_radius)\r\n      cv2.circle(im_rgb,center,radius,(0,255,255))\r\n      \r\n      #fitEllipse\r\n      cv2.ellipse(im_rgb,ellipse,(255,0,255))   \r\n    \r\n    return { \u0027image\u0027 : im_rgb }          \r\n\nvar_imread_1 \u003d imread(1)\nvar_imageReference_2 \u003d imageReference(var_imread_1[\u0027image\u0027],1,50)\nvar_cvtColor_3 \u003d cvtColor(var_imageReference_2[\u0027image\u0027],6L)\nvar_standardResult_4 \u003d standardResult(var_cvtColor_3[\u0027image\u0027],(0.0, 0.0, \u0027m\u0027))\n\u003c/Code\u003e\r\n\u003c/FlowView\u003e"
}
{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 11,
    "imageAnalysisProcessingname": "Imagerie20150429_PetitesPlantes"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "Imagerie petites plantes (14 jours apres semis)",
  "processingScript": "\u003cFlowView\u003e\u003cNode id\u003d\"54172779\" name\u003d\"NodeOpenCV.imread\" x\u003d\"40\" y\u003d\"161\"\u003e\u003cflags value\u003d\"1\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"65303132\" name\u003d\"NodeOpenCV.background\" x\u003d\"366\" y\u003d\"146\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"29365919\" /\u003e\u003cbackground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107), (69, 137, 218), (170, 183, 184), (255, 255, 255), (224, 229, 232), (150, 156, 157)])\" /\u003e\u003cforeground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (38, 50, 43), (24, 68, 54), (59, 116, 87), (134, 144, 116), (103, 115, 97), (84, 103, 80), (79, 95, 70), (126, 126, 100), (99, 98, 72), (105, 99, 76), (105, 99, 76), (121, 112, 93), (90, 172, 152)])\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"10497067\" name\u003d\"NodeOpenCV.morphology\" x\u003d\"522\" y\u003d\"149\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"65303132\" /\u003e\u003coperation value\u003d\"open\" /\u003e\u003csize value\u003d\"2\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"51692872\" name\u003d\"NodeOpenCV.fillHoles\" x\u003d\"687\" y\u003d\"150\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"10497067\" /\u003e\u003cmin_filter value\u003d\"0\" /\u003e\u003cmax_filter value\u003d\"10000\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"29365919\" name\u003d\"NodeOpenCV.crop\" x\u003d\"207\" y\u003d\"144\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"54172779\" /\u003e\u003ctl value\u003d\"(529, 576)\" /\u003e\u003cbr value\u003d\"(1556, 1812)\" /\u003e\u003cshape value\u003d\"Rectangle\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"52630025\" name\u003d\"NodeOpenCV.standardResult\" x\u003d\"851\" y\u003d\"160\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"51692872\" /\u003e\u003cscale value\u003d\"(0.0, 0.0, \u0027\u0027)\" /\u003e\u003c/Node\u003e\u003cCode\u003eimport cv2\r\nimport sys\r\nimport vp\r\nimport numpy as np\r\nimport vp2\r\nimport VpTypes\r\nimport math\r\ndef imread(flags):\r\n\r\n    vp.debug( repr( sys.argv ) )\r\n    im \u003d cv2.imread( sys.argv[1], flags )\r\n    return { \u0027image\u0027 : im }\r\n  \r\ndef crop(image,tl,br,shape):\r\n\r\n    vp.debug( repr( ( tl, br ) ) )\r\n    mask \u003d np.zeros( (image.shape[0],image.shape[1]), np.uint8)\r\n    x1 \u003d min(tl[0],br[0])\r\n    y1 \u003d min(tl[1],br[1])\r\n    x2 \u003d max(tl[0],br[0])\r\n    y2 \u003d max(tl[1],br[1])\r\n    if shape \u003d\u003d 1:\r\n      cv2.rectangle(mask,(x1,y1),(x2,y2),(255,255,255),-1)\r\n    else:\r\n      cx \u003d x1 + (x2-x1) / 2.0\r\n      cy \u003d y1 + (y2-y1) / 2.0\r\n      cv2.ellipse(mask,((cx,cy),(x2-x1,y2-y1),0), (255,255,255), -1)\r\n    im_final \u003d cv2.bitwise_and(image,image,mask \u003d mask)\r\n    return { \u0027image\u0027 : im_final }\r\n    \r\ndef background(image,background,foreground):\r\n\r\n    #Add back and fore ground\r\n    selection \u003d background.ColorList + foreground.ColorList\r\n    \r\n    if len(selection)\u0026lt;1:\r\n      return\r\n\r\n    #Convert color selection to L*a*b\r\n    sel \u003d cv2.cvtColor( np.array([selection],dtype\u003d\u0027uint8\u0027), cv2.COLOR_BGR2LAB ).astype(\"float32\")[0]\r\n\r\n    #Convert image to L*a*b\r\n    src \u003d cv2.cvtColor( image, cv2.COLOR_BGR2LAB )\r\n\r\n\t  #find index of near euclidian distance to each color pixel    \r\n    weights \u003d np.ones( len(sel), dtype\u003d\u0027float\u0027 )\r\n    #weights \u003d np.array( [1.0]*len(background.ColorList)+[2.0]*len(foreground.ColorList), dtype\u003d\u0027float\u0027 )\r\n    ( results, dst ) \u003d vp2.colorClassification( src, sel.tolist(), weights )\r\n\r\n    #find the minimal\r\n    backOrForeground \u003d np.array( [0] * len(background.ColorList) + [255] * len(foreground.ColorList), dtype\u003d\u0027uint8\u0027 )\r\n    label \u003d backOrForeground[ dst ]\r\n        \r\n    return { \u0027image\u0027 : label }\r\n    \r\ndef morphology(image,operation,size):\r\n\r\n    kernel \u003d cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(size,size))  \r\n    im \u003d cv2.morphologyEx( image, operation, kernel )\r\n    return { \u0027image\u0027 : im }\r\n  \r\ndef fillHoles(image,min_filter,max_filter):\r\n    \r\n    #findContours function erase input image so clone it\r\n    clone1 \u003d np.copy(image)\r\n    clone2 \u003d np.copy(image)\r\n    contours,hierarchy \u003d cv2.findContours( clone1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\r\n\r\n    for (i,cnt) in enumerate(contours):\r\n      parent \u003d hierarchy[0,i,3]\r\n      if parent !\u003d -1 : #has parent so it is hole\r\n        area \u003d cv2.contourArea(cnt)\r\n        if area\u0026gt;min_filter and area\u0026lt;max_filter:\r\n          cv2.drawContours(clone2,[cnt],0,(255,255,255),-1)\r\n          \r\n    return { \u0027image\u0027 : clone2 }          \r\n\r\ndef standardResult(image,scale):\r\n    \r\n    if ( len(image.shape) \u0026gt; 2 ):\r\n      raise Exception(\u0027Input image must be monochrom\u0027)\r\n            \r\n    contours,hierarchy \u003d cv2.findContours( np.copy(image), cv2.cv.CV_RETR_EXTERNAL, cv2.cv.CV_CHAIN_APPROX_SIMPLE )\r\n      \r\n    if ( len(contours)\u0026lt;1 ):\r\n      return { \u0027image\u0027 : image }          \r\n    \r\n    #Merge Contours\r\n    concat_contours \u003d contours[0]\r\n    for cnt in contours[1:]:\r\n      if len(cnt)\u0026gt;3:\r\n\t      concat_contours \u003d np.concatenate( [concat_contours, cnt] )\r\n        \r\n    pb_x,pb_y,pb_w,pb_h \u003d cv2.boundingRect(concat_contours)\r\n    \r\n    rect \u003d cv2.minAreaRect( concat_contours )\r\n    (np_x,np_y),(np_w,np_h),np_teta \u003d rect\r\n    \r\n    center_x, center_y, leafarea \u003d vp2.centerOfGravity(image)\r\n    \r\n    (mec_x,mec_y),mec_radius \u003d cv2.minEnclosingCircle(concat_contours)\r\n    \r\n    ellipse \u003d ((-1,-1),(-1,-1),-1)\r\n    if len(concat_contours)\u0026gt;5:\r\n      ellipse \u003d cv2.fitEllipse(concat_contours)\r\n    (ell_x,ell_y),(ell_w,ell_h),ell_teta \u003d ellipse\r\n    \r\n    hull \u003d cv2.convexHull(concat_contours)\r\n    \r\n    #Save binary image    \r\n    if vp.is_script():\r\n      cv2.imwrite( sys.argv[2], image )\r\n    \r\n    #Results generate\r\n    results \u003d { \r\n      \u0027xscale\u0027 : scale[0],\r\n      \u0027yscale\u0027 : scale[1],\r\n      \u0027unitscale\u0027 : scale[2],\r\n      \r\n      \u0027parallelboundingbox_x\u0027 : pb_x,\r\n      \u0027parallelboundingbox_y\u0027 : pb_y,\r\n      \u0027parallelboundingbox_width\u0027 : pb_w,\r\n      \u0027parallelboundingbox_height\u0027 : pb_h,\r\n      \u0027parallelboundingbox_area\u0027 : pb_w*pb_h,\r\n      \r\n      \u0027nonparallelboundingbox_x\u0027 : np_x,\r\n      \u0027nonparallelboundingbox_y\u0027 : np_y,\r\n      \u0027nonparallelboundingbox_width\u0027 : np_w,\r\n      \u0027nonparallelboundingbox_height\u0027 : np_h,\r\n      \u0027nonparallelboundingbox_area\u0027 : np_w*np_h,\r\n      \u0027nonparallelboundingbox_teta\u0027 : np_teta,\r\n      \r\n      \u0027height\u0027 : 0,\r\n      \r\n      \u0027centerofmassx\u0027 : center_x,\r\n      \u0027centerofmassy\u0027 : center_y,\r\n      \r\n      \u0027area_color_1\u0027 : leafarea,\r\n      \u0027area_color_2\u0027 : 0,\r\n      \r\n      \u0027fitellipse_x\u0027 : ell_x,\r\n      \u0027fitellipse_y\u0027 : ell_y,\r\n      \u0027fitellipse_width\u0027 : ell_w,\r\n      \u0027fitellipse_height\u0027 : ell_h,\r\n      \u0027fitellipse_teta\u0027 : ell_teta,\r\n      \u0027fitellipse_area\u0027 : ( math.pi * ell_w * ell_h ) / 4.,\r\n      \r\n      \u0027minenclosingcircle_x\u0027 : mec_x,\r\n      \u0027minenclosingcircle_y\u0027 : mec_y,\r\n      \u0027minenclosingcircle_radius\u0027 : mec_radius,\r\n      \u0027minenclosingcircle_area\u0027 : math.pi * mec_radius * mec_radius,\r\n      \r\n      \u0027convexhull\u0027 : hull.tolist(),      \r\n      \r\n      }\r\n      \r\n    #Results\r\n    sys.stdout.write ( \u0027\\t\u0027.join([ \"%s|\" % k + str(v) for k,v in results.iteritems() ]) )      \r\n      \r\n    #Draw\r\n    im_rgb \u003d None\r\n    if not vp.is_script():\r\n      im_rgb \u003d cv2.cvtColor( image, cv2.COLOR_GRAY2BGR )\r\n    \r\n      #Center Of gravity\r\n      cog_size \u003d 2\r\n      cv2.line( im_rgb, ( int(center_x) - cog_size, int(center_y) - cog_size ), ( int(center_x) + cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n      cv2.line( im_rgb, ( int(center_x) + cog_size, int(center_y) - cog_size ), ( int(center_x) - cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n    \r\n      #hori rect\r\n      cv2.rectangle(im_rgb,(pb_x,pb_y),(pb_x+pb_w,pb_y+pb_h),(255,0,0))\r\n      #rotate rect\r\n      box \u003d cv2.cv.BoxPoints(rect)\r\n      box \u003d np.int0(box)\r\n      cv2.drawContours(im_rgb,[box],0,(0,0,255))\r\n    \r\n      #Hull\r\n      hull \u003d cv2.convexHull(concat_contours)\r\n      cv2.drawContours(im_rgb,[hull],0,(0,255,0))\r\n    \r\n      #minEnclosingCircle\r\n      center \u003d (int(mec_x),int(mec_y))\r\n      radius \u003d int(mec_radius)\r\n      cv2.circle(im_rgb,center,radius,(0,255,255))\r\n      \r\n      #fitEllipse\r\n      cv2.ellipse(im_rgb,ellipse,(255,0,255))   \r\n    \r\n    return { \u0027image\u0027 : im_rgb }          \r\n\r\nvar_imread_7 \u003d imread(1)\r\nvar_crop_8 \u003d crop(var_imread_7[\u0027image\u0027],(529, 576),(1556, 1812),1)\r\nvar_background_9 \u003d background(var_crop_8[\u0027image\u0027],VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107), (69, 137, 218), (170, 183, 184), (255, 255, 255), (224, 229, 232), (150, 156, 157)]),VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (38, 50, 43), (24, 68, 54), (59, 116, 87), (134, 144, 116), (103, 115, 97), (84, 103, 80), (79, 95, 70), (126, 126, 100), (99, 98, 72), (105, 99, 76), (105, 99, 76), (121, 112, 93), (90, 172, 152)]))\r\nvar_morphology_10 \u003d morphology(var_background_9[\u0027image\u0027],2L,2)\r\nvar_fillHoles_11 \u003d fillHoles(var_morphology_10[\u0027image\u0027],0,10000)\r\nvar_standardResult_12 \u003d standardResult(var_fillHoles_11[\u0027image\u0027],(0.0, 0.0, \u0027\u0027))\r\n\u003c/Code\u003e\u003c/FlowView\u003e"
}
{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 12,
    "imageAnalysisProcessingname": "201504"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "Profil imagerie plantes 14 jours apres semis",
  "processingScript": "\u003cFlowView\u003e\u003cNode id\u003d\"54172779\" name\u003d\"NodeOpenCV.imread\" x\u003d\"-167\" y\u003d\"164\"\u003e\u003cflags value\u003d\"1\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"65303132\" name\u003d\"NodeOpenCV.background\" x\u003d\"366\" y\u003d\"146\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"29365919\" /\u003e\u003cbackground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107), (69, 137, 218), (170, 183, 184), (255, 255, 255), (143, 113, 101), (56, 44, 48), (48, 33, 33), (154, 148, 144), (162, 161, 162), (120, 147, 156), (119, 126, 131), (102, 104, 103), (181, 187, 180), (175, 104, 79), (168, 102, 73), (201, 116, 88)])\" /\u003e\u003cforeground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (24, 68, 54), (59, 116, 87), (90, 172, 152), (40, 202, 110), (9, 191, 88), (5, 171, 77), (57, 248, 140), (2, 119, 53), (132, 176, 163), (141, 155, 150), (124, 161, 155), (114, 132, 104), (180, 194, 174), (93, 91, 67), (84, 168, 145), (99, 106, 84)])\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"51692872\" name\u003d\"NodeOpenCV.fillHoles\" x\u003d\"542\" y\u003d\"141\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"65303132\" /\u003e\u003cmin_filter value\u003d\"3\" /\u003e\u003cmax_filter value\u003d\"100000\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"29365919\" name\u003d\"NodeOpenCV.crop\" x\u003d\"207\" y\u003d\"144\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"34343508\" /\u003e\u003ctl value\u003d\"(354, 380)\" /\u003e\u003cbr value\u003d\"(1698, 1897)\" /\u003e\u003cshape value\u003d\"Rectangle\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"52630025\" name\u003d\"NodeOpenCV.standardResult\" x\u003d\"893\" y\u003d\"150\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"1740610\" /\u003e\u003cscale value\u003d\"(0.0, 0.0, \u0027\u0027)\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"34343508\" name\u003d\"NodeOpenCV.imageReference\" x\u003d\"8\" y\u003d\"157\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"54172779\" /\u003e\u003cflags value\u003d\"1\" /\u003e\u003cthreshold_value value\u003d\"50\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"1740610\" name\u003d\"NodeOpenCV.morphology\" x\u003d\"718\" y\u003d\"145\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"51692872\" /\u003e\u003coperation value\u003d\"open\" /\u003e\u003csize value\u003d\"3\" /\u003e\u003c/Node\u003e\u003cCode\u003eimport cv2\r\nimport sys\r\nimport vp\r\nimport numpy as np\r\nimport vp2\r\nimport VpTypes\r\nimport math\r\ndef imread(flags):\r\n\r\n    vp.debug( repr( sys.argv ) )\r\n    im \u003d cv2.imread( sys.argv[1], flags )\r\n    return { \u0027image\u0027 : im }\r\n  \r\ndef imageReference(image,flags,threshold_value):\r\n    \r\n    #Read image reference in grayscale\r\n    vp.debug( repr( sys.argv ) )\r\n    im_ref \u003d cv2.imread( sys.argv[3], cv2.IMREAD_GRAYSCALE )\r\n    #Convert input image into grayscale\r\n    im_gray \u003d cv2.cvtColor( image, cv2.COLOR_BGR2GRAY )\r\n    \r\n    vp.debug( repr( im_ref.shape ) )\r\n    vp.debug( repr( im_gray.shape ) )\r\n    \r\n    #Make image difference \r\n    im_diff \u003d cv2.absdiff(im_gray,im_ref)\r\n    #Apply threshold\r\n    ret, im_thres \u003d cv2.threshold( im_diff, threshold_value, 255, cv2.THRESH_BINARY )\r\n    #Apply mask\r\n    im_final \u003d cv2.bitwise_and(image,image,mask \u003d im_thres)\r\n    return { \u0027image\u0027 : im_final }\r\n    \r\ndef crop(image,tl,br,shape):\r\n\r\n    vp.debug( repr( ( tl, br ) ) )\r\n    mask \u003d np.zeros( (image.shape[0],image.shape[1]), np.uint8)\r\n    x1 \u003d min(tl[0],br[0])\r\n    y1 \u003d min(tl[1],br[1])\r\n    x2 \u003d max(tl[0],br[0])\r\n    y2 \u003d max(tl[1],br[1])\r\n    if shape \u003d\u003d 1:\r\n      cv2.rectangle(mask,(x1,y1),(x2,y2),(255,255,255),-1)\r\n    else:\r\n      cx \u003d x1 + (x2-x1) / 2.0\r\n      cy \u003d y1 + (y2-y1) / 2.0\r\n      cv2.ellipse(mask,((cx,cy),(x2-x1,y2-y1),0), (255,255,255), -1)\r\n    im_final \u003d cv2.bitwise_and(image,image,mask \u003d mask)\r\n    return { \u0027image\u0027 : im_final }\r\n    \r\ndef background(image,background,foreground):\r\n\r\n    #Add back and fore ground\r\n    selection \u003d background.ColorList + foreground.ColorList\r\n    \r\n    if len(selection)\u0026lt;1:\r\n      return\r\n\r\n    #Convert color selection to L*a*b\r\n    sel \u003d cv2.cvtColor( np.array([selection],dtype\u003d\u0027uint8\u0027), cv2.COLOR_BGR2LAB ).astype(\"float32\")[0]\r\n\r\n    #Convert image to L*a*b\r\n    src \u003d cv2.cvtColor( image, cv2.COLOR_BGR2LAB )\r\n\r\n\t  #find index of near euclidian distance to each color pixel    \r\n    weights \u003d np.ones( len(sel), dtype\u003d\u0027float\u0027 )\r\n    #weights \u003d np.array( [1.0]*len(background.ColorList)+[2.0]*len(foreground.ColorList), dtype\u003d\u0027float\u0027 )\r\n    ( results, dst ) \u003d vp2.colorClassification( src, sel.tolist(), weights )\r\n\r\n    #find the minimal\r\n    backOrForeground \u003d np.array( [0] * len(background.ColorList) + [255] * len(foreground.ColorList), dtype\u003d\u0027uint8\u0027 )\r\n    label \u003d backOrForeground[ dst ]\r\n        \r\n    return { \u0027image\u0027 : label }\r\n    \r\ndef fillHoles(image,min_filter,max_filter):\r\n    \r\n    #findContours function erase input image so clone it\r\n    clone1 \u003d np.copy(image)\r\n    clone2 \u003d np.copy(image)\r\n    contours,hierarchy \u003d cv2.findContours( clone1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\r\n\r\n    for (i,cnt) in enumerate(contours):\r\n      parent \u003d hierarchy[0,i,3]\r\n      if parent !\u003d -1 : #has parent so it is hole\r\n        area \u003d cv2.contourArea(cnt)\r\n        if area\u0026gt;min_filter and area\u0026lt;max_filter:\r\n          cv2.drawContours(clone2,[cnt],0,(255,255,255),-1)\r\n          \r\n    return { \u0027image\u0027 : clone2 }          \r\n\r\ndef morphology(image,operation,size):\r\n\r\n    kernel \u003d cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(size,size))  \r\n    im \u003d cv2.morphologyEx( image, operation, kernel )\r\n    return { \u0027image\u0027 : im }\r\n  \r\ndef standardResult(image,scale):\r\n    \r\n    if ( len(image.shape) \u0026gt; 2 ):\r\n      raise Exception(\u0027Input image must be monochrom\u0027)\r\n            \r\n    contours,hierarchy \u003d cv2.findContours( np.copy(image), cv2.cv.CV_RETR_EXTERNAL, cv2.cv.CV_CHAIN_APPROX_SIMPLE )\r\n      \r\n    if ( len(contours)\u0026lt;1 ):\r\n      return { \u0027image\u0027 : image }          \r\n    \r\n    #Merge Contours\r\n    concat_contours \u003d contours[0]\r\n    for cnt in contours[1:]:\r\n      if len(cnt)\u0026gt;3:\r\n\t      concat_contours \u003d np.concatenate( [concat_contours, cnt] )\r\n        \r\n    pb_x,pb_y,pb_w,pb_h \u003d cv2.boundingRect(concat_contours)\r\n    \r\n    rect \u003d cv2.minAreaRect( concat_contours )\r\n    (np_x,np_y),(np_w,np_h),np_teta \u003d rect\r\n    \r\n    center_x, center_y, leafarea \u003d vp2.centerOfGravity(image)\r\n    \r\n    (mec_x,mec_y),mec_radius \u003d cv2.minEnclosingCircle(concat_contours)\r\n    \r\n    ellipse \u003d ((-1,-1),(-1,-1),-1)\r\n    if len(concat_contours)\u0026gt;5:\r\n      ellipse \u003d cv2.fitEllipse(concat_contours)\r\n    (ell_x,ell_y),(ell_w,ell_h),ell_teta \u003d ellipse\r\n    \r\n    hull \u003d cv2.convexHull(concat_contours)\r\n    \r\n    #Save binary image    \r\n    if vp.is_script():\r\n      cv2.imwrite( sys.argv[2], image )\r\n    \r\n    #Results generate\r\n    results \u003d { \r\n      \u0027xscale\u0027 : scale[0],\r\n      \u0027yscale\u0027 : scale[1],\r\n      \u0027unitscale\u0027 : scale[2],\r\n      \r\n      \u0027parallelboundingbox_x\u0027 : pb_x,\r\n      \u0027parallelboundingbox_y\u0027 : pb_y,\r\n      \u0027parallelboundingbox_width\u0027 : pb_w,\r\n      \u0027parallelboundingbox_height\u0027 : pb_h,\r\n      \u0027parallelboundingbox_area\u0027 : pb_w*pb_h,\r\n      \r\n      \u0027nonparallelboundingbox_x\u0027 : np_x,\r\n      \u0027nonparallelboundingbox_y\u0027 : np_y,\r\n      \u0027nonparallelboundingbox_width\u0027 : np_w,\r\n      \u0027nonparallelboundingbox_height\u0027 : np_h,\r\n      \u0027nonparallelboundingbox_area\u0027 : np_w*np_h,\r\n      \u0027nonparallelboundingbox_teta\u0027 : np_teta,\r\n      \r\n      \u0027height\u0027 : 0,\r\n      \r\n      \u0027centerofmassx\u0027 : center_x,\r\n      \u0027centerofmassy\u0027 : center_y,\r\n      \r\n      \u0027area_color_1\u0027 : leafarea,\r\n      \u0027area_color_2\u0027 : 0,\r\n      \r\n      \u0027fitellipse_x\u0027 : ell_x,\r\n      \u0027fitellipse_y\u0027 : ell_y,\r\n      \u0027fitellipse_width\u0027 : ell_w,\r\n      \u0027fitellipse_height\u0027 : ell_h,\r\n      \u0027fitellipse_teta\u0027 : ell_teta,\r\n      \u0027fitellipse_area\u0027 : ( math.pi * ell_w * ell_h ) / 4.,\r\n      \r\n      \u0027minenclosingcircle_x\u0027 : mec_x,\r\n      \u0027minenclosingcircle_y\u0027 : mec_y,\r\n      \u0027minenclosingcircle_radius\u0027 : mec_radius,\r\n      \u0027minenclosingcircle_area\u0027 : math.pi * mec_radius * mec_radius,\r\n      \r\n      \u0027convexhull\u0027 : hull.tolist(),      \r\n      \r\n      }\r\n      \r\n    #Results\r\n    sys.stdout.write ( \u0027\\t\u0027.join([ \"%s|\" % k + str(v) for k,v in results.iteritems() ]) )      \r\n      \r\n    #Draw\r\n    im_rgb \u003d None\r\n    if not vp.is_script():\r\n      im_rgb \u003d cv2.cvtColor( image, cv2.COLOR_GRAY2BGR )\r\n    \r\n      #Center Of gravity\r\n      cog_size \u003d 2\r\n      cv2.line( im_rgb, ( int(center_x) - cog_size, int(center_y) - cog_size ), ( int(center_x) + cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n      cv2.line( im_rgb, ( int(center_x) + cog_size, int(center_y) - cog_size ), ( int(center_x) - cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n    \r\n      #hori rect\r\n      cv2.rectangle(im_rgb,(pb_x,pb_y),(pb_x+pb_w,pb_y+pb_h),(255,0,0))\r\n      #rotate rect\r\n      box \u003d cv2.cv.BoxPoints(rect)\r\n      box \u003d np.int0(box)\r\n      cv2.drawContours(im_rgb,[box],0,(0,0,255))\r\n    \r\n      #Hull\r\n      hull \u003d cv2.convexHull(concat_contours)\r\n      cv2.drawContours(im_rgb,[hull],0,(0,255,0))\r\n    \r\n      #minEnclosingCircle\r\n      center \u003d (int(mec_x),int(mec_y))\r\n      radius \u003d int(mec_radius)\r\n      cv2.circle(im_rgb,center,radius,(0,255,255))\r\n      \r\n      #fitEllipse\r\n      cv2.ellipse(im_rgb,ellipse,(255,0,255))   \r\n    \r\n    return { \u0027image\u0027 : im_rgb }          \r\n\r\nvar_imread_15 \u003d imread(1)\r\nvar_imageReference_16 \u003d imageReference(var_imread_15[\u0027image\u0027],1,50)\r\nvar_crop_17 \u003d crop(var_imageReference_16[\u0027image\u0027],(354, 380),(1698, 1897),1)\r\nvar_background_18 \u003d background(var_crop_17[\u0027image\u0027],VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107), (69, 137, 218), (170, 183, 184), (255, 255, 255), (143, 113, 101), (56, 44, 48), (48, 33, 33), (154, 148, 144), (162, 161, 162), (120, 147, 156), (119, 126, 131), (102, 104, 103), (181, 187, 180), (175, 104, 79), (168, 102, 73), (201, 116, 88)]),VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (24, 68, 54), (59, 116, 87), (90, 172, 152), (40, 202, 110), (9, 191, 88), (5, 171, 77), (57, 248, 140), (2, 119, 53), (132, 176, 163), (141, 155, 150), (124, 161, 155), (114, 132, 104), (180, 194, 174), (93, 91, 67), (84, 168, 145), (99, 106, 84)]))\r\nvar_fillHoles_19 \u003d fillHoles(var_background_18[\u0027image\u0027],3,100000)\r\nvar_morphology_20 \u003d morphology(var_fillHoles_19[\u0027image\u0027],2L,3)\r\nvar_standardResult_21 \u003d standardResult(var_morphology_20[\u0027image\u0027],(0.0, 0.0, \u0027\u0027))\r\n\u003c/Code\u003e\u003c/FlowView\u003e"
}
{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 10,
    "imageAnalysisProcessingname": "stdResult"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "",
  "processingScript": "\u003cFlowView\u003e\r\n  \u003cNode id\u003d\"54172779\" name\u003d\"NodeOpenCV.imread\" x\u003d\"61\" y\u003d\"159\"\u003e\r\n    \u003cflags value\u003d\"1\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"41253532\" name\u003d\"NodeOpenCV.standardResult\" x\u003d\"714\" y\u003d\"152\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"8557861\" /\u003e\r\n    \u003cscale value\u003d\"(0.0, 0.0, \u0027m\u0027)\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"23909939\" name\u003d\"NodeOpenCV.imageReference\" x\u003d\"245\" y\u003d\"153\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"54172779\" /\u003e\r\n    \u003cflags value\u003d\"1\" /\u003e\r\n    \u003cthreshold_value value\u003d\"50\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cNode id\u003d\"8557861\" name\u003d\"NodeOpenCV.cvtColor\" x\u003d\"458\" y\u003d\"154\"\u003e\r\n    \u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"23909939\" /\u003e\r\n    \u003ccolor_space_conversion value\u003d\"BGR2GRAY\" /\u003e\r\n  \u003c/Node\u003e\r\n  \u003cCode\u003eimport cv2\nimport sys\nimport vp\nimport vp2\nimport math\nimport numpy as np\ndef imread(flags):\n\r\n    vp.debug( repr( sys.argv ) )\r\n    im \u003d cv2.imread( sys.argv[1], flags )\r\n    return { \u0027image\u0027 : im }\r\n  \ndef imageReference(image,flags,threshold_value):\n\r\n    vp.debug( repr( sys.argv ) )\r\n    #Read image reference in grayscale\r\n    im_ref \u003d cv2.imread( sys.argv[3], cv2.IMREAD_GRAYSCALE )\r\n    #Convert input image into grayscale\r\n    im_gray \u003d cv2.cvtColor( image, cv2.COLOR_BGR2GRAY )\r\n    #Make image difference \r\n    im_diff \u003d cv2.absdiff(im_gray,im_ref)\r\n    #Apply threshold\r\n    ret, im_thres \u003d cv2.threshold( im_diff, threshold_value, 255, cv2.THRESH_BINARY )\r\n    #Apply mask\r\n    im_final \u003d cv2.bitwise_and(image,image,mask \u003d im_thres)\r\n    return { \u0027image\u0027 : im_final }\r\n    \ndef cvtColor(image,color_space_conversion):\n\r\n    im \u003d cv2.cvtColor( image, color_space_conversion )\r\n    return { \u0027image\u0027 : im }\r\n  \ndef standardResult(image,scale):\n    \r\n    if ( len(image.shape) \u0026gt; 2 ):\r\n      raise Exception(\u0027Input image must be monochrom\u0027)\r\n            \r\n    contours,hierarchy \u003d cv2.findContours( np.copy(image), cv2.cv.CV_RETR_EXTERNAL, cv2.cv.CV_CHAIN_APPROX_SIMPLE )\r\n      \r\n    if ( len(contours)\u0026lt;1 ):\r\n      return { \u0027image\u0027 : image }          \r\n    \r\n    #Merge Contours\r\n    concat_contours \u003d contours[0]\r\n    for cnt in contours[1:]:\r\n\t    concat_contours \u003d np.concatenate( [concat_contours, cnt] )\r\n        \r\n    pb_x,pb_y,pb_w,pb_h \u003d cv2.boundingRect(concat_contours)\r\n    \r\n    rect \u003d cv2.minAreaRect( concat_contours )\r\n    (np_x,np_y),(np_w,np_h),np_teta \u003d rect\r\n    \r\n    center_x, center_y, leafarea \u003d vp2.centerOfGravity(image)\r\n    \r\n    (mec_x,mec_y),mec_radius \u003d cv2.minEnclosingCircle(concat_contours)\r\n    \r\n    ellipse \u003d ((-1,-1),(-1,-1),-1)\r\n    if len(concat_contours)\u0026gt;5:\r\n      ellipse \u003d cv2.fitEllipse(concat_contours)\r\n    (ell_x,ell_y),(ell_w,ell_h),ell_teta \u003d ellipse\r\n    \r\n    hull \u003d cv2.convexHull(concat_contours)\r\n    \r\n    #Save binary image    \r\n    if vp.is_script():\r\n      cv2.imwrite( sys.argv[2], image )\r\n    \r\n    #Results generate\r\n    results \u003d { \r\n      \u0027xscale\u0027 : scale[0],\r\n      \u0027yscale\u0027 : scale[1],\r\n      \u0027unitscale\u0027 : scale[2],\r\n      \r\n      \u0027parallelboundingbox_x\u0027 : pb_x,\r\n      \u0027parallelboundingbox_y\u0027 : pb_y,\r\n      \u0027parallelboundingbox_width\u0027 : pb_w,\r\n      \u0027parallelboundingbox_height\u0027 : pb_h,\r\n      \u0027parallelboundingbox_area\u0027 : pb_w*pb_h,\r\n      \r\n      \u0027nonparallelboundingbox_x\u0027 : np_x,\r\n      \u0027nonparallelboundingbox_y\u0027 : np_y,\r\n      \u0027nonparallelboundingbox_width\u0027 : np_w,\r\n      \u0027nonparallelboundingbox_height\u0027 : np_h,\r\n      \u0027nonparallelboundingbox_area\u0027 : np_w*np_h,\r\n      \u0027nonparallelboundingbox_teta\u0027 : np_teta,\r\n      \r\n      \u0027height\u0027 : 0,\r\n      \r\n      \u0027centerofmassx\u0027 : center_x,\r\n      \u0027centerofmassy\u0027 : center_y,\r\n      \r\n      \u0027area_color_1\u0027 : leafarea,\r\n      \u0027area_color_2\u0027 : 0,\r\n      \r\n      \u0027fitellipse_x\u0027 : ell_x,\r\n      \u0027fitellipse_y\u0027 : ell_y,\r\n      \u0027fitellipse_width\u0027 : ell_w,\r\n      \u0027fitellipse_height\u0027 : ell_h,\r\n      \u0027fitellipse_teta\u0027 : ell_teta,\r\n      \u0027fitellipse_area\u0027 : ( math.pi * ell_w * ell_h ) / 4.,\r\n      \r\n      \u0027minenclosingcircle_x\u0027 : mec_x,\r\n      \u0027minenclosingcircle_y\u0027 : mec_y,\r\n      \u0027minenclosingcircle_radius\u0027 : mec_radius,\r\n      \u0027minenclosingcircle_area\u0027 : math.pi * mec_radius * mec_radius,\r\n      \r\n      \u0027convexhull\u0027 : hull.tolist(),      \r\n      \r\n      }\r\n      \r\n    #Results\r\n    sys.stdout.write ( \u0027\\t\u0027.join([ \"%s|\" % k + str(v) for k,v in results.iteritems() ]) )      \r\n      \r\n    #Draw\r\n    im_rgb \u003d None\r\n    if not vp.is_script():\r\n      im_rgb \u003d cv2.cvtColor( image, cv2.COLOR_GRAY2BGR )\r\n    \r\n      #Center Of gravity\r\n      cog_size \u003d 2\r\n      cv2.line( im_rgb, ( int(center_x) - cog_size, int(center_y) - cog_size ), ( int(center_x) + cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n      cv2.line( im_rgb, ( int(center_x) + cog_size, int(center_y) - cog_size ), ( int(center_x) - cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n    \r\n      #hori rect\r\n      cv2.rectangle(im_rgb,(pb_x,pb_y),(pb_x+pb_w,pb_y+pb_h),(255,0,0))\r\n      #rotate rect\r\n      box \u003d cv2.cv.BoxPoints(rect)\r\n      box \u003d np.int0(box)\r\n      cv2.drawContours(im_rgb,[box],0,(0,0,255))\r\n    \r\n      #Hull\r\n      hull \u003d cv2.convexHull(concat_contours)\r\n      cv2.drawContours(im_rgb,[hull],0,(0,255,0))\r\n    \r\n      #minEnclosingCircle\r\n      center \u003d (int(mec_x),int(mec_y))\r\n      radius \u003d int(mec_radius)\r\n      cv2.circle(im_rgb,center,radius,(0,255,255))\r\n      \r\n      #fitEllipse\r\n      cv2.ellipse(im_rgb,ellipse,(255,0,255))   \r\n    \r\n    return { \u0027image\u0027 : im_rgb }          \r\n\nvar_imread_1 \u003d imread(1)\nvar_imageReference_2 \u003d imageReference(var_imread_1[\u0027image\u0027],1,50)\nvar_cvtColor_3 \u003d cvtColor(var_imageReference_2[\u0027image\u0027],6L)\nvar_standardResult_4 \u003d standardResult(var_cvtColor_3[\u0027image\u0027],(0.0, 0.0, \u0027m\u0027))\n\u003c/Code\u003e\r\n\u003c/FlowView\u003e"
}
{
  "configuration": {
    "provider": "phenowaredb",
    "imageAnalysisProcessingid": 13,
    "imageAnalysisProcessingname": "Imagerie20150429_PetitesPlantes2"
  },
  "validatedProcess": true,
  "deletedProcess": true,
  "description": "Imagerie petites plantes (14 jours apres semis) corrige",
  "processingScript": "\u003cFlowView\u003e\u003cNode id\u003d\"54172779\" name\u003d\"NodeOpenCV.imread\" x\u003d\"40\" y\u003d\"161\"\u003e\u003cflags value\u003d\"1\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"65303132\" name\u003d\"NodeOpenCV.background\" x\u003d\"366\" y\u003d\"146\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"29365919\" /\u003e\u003cbackground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107), (69, 137, 218), (170, 183, 184), (255, 255, 255), (224, 229, 232), (150, 156, 157), (138, 147, 139)])\" /\u003e\u003cforeground value\u003d\"VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (38, 50, 43), (24, 68, 54), (59, 116, 87), (134, 144, 116), (103, 115, 97), (84, 103, 80), (79, 95, 70), (126, 126, 100), (99, 98, 72), (105, 99, 76), (105, 99, 76), (121, 112, 93), (90, 172, 152)])\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"10497067\" name\u003d\"NodeOpenCV.morphology\" x\u003d\"522\" y\u003d\"149\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"65303132\" /\u003e\u003coperation value\u003d\"open\" /\u003e\u003csize value\u003d\"2\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"51692872\" name\u003d\"NodeOpenCV.fillHoles\" x\u003d\"687\" y\u003d\"150\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"10497067\" /\u003e\u003cmin_filter value\u003d\"0\" /\u003e\u003cmax_filter value\u003d\"10000\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"29365919\" name\u003d\"NodeOpenCV.crop\" x\u003d\"207\" y\u003d\"144\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"54172779\" /\u003e\u003ctl value\u003d\"(529, 576)\" /\u003e\u003cbr value\u003d\"(1556, 1812)\" /\u003e\u003cshape value\u003d\"Rectangle\" /\u003e\u003c/Node\u003e\u003cNode id\u003d\"52630025\" name\u003d\"NodeOpenCV.standardResult\" x\u003d\"851\" y\u003d\"160\"\u003e\u003cConnection source\u003d\"image\" destination\u003d\"image\" source_id\u003d\"51692872\" /\u003e\u003cscale value\u003d\"(0.01, 0.01, \u0027cm\u0027)\" /\u003e\u003c/Node\u003e\u003cCode\u003eimport cv2\r\nimport sys\r\nimport vp\r\nimport numpy as np\r\nimport vp2\r\nimport VpTypes\r\nimport math\r\ndef imread(flags):\r\n\r\n    vp.debug( repr( sys.argv ) )\r\n    im \u003d cv2.imread( sys.argv[1], flags )\r\n    return { \u0027image\u0027 : im }\r\n  \r\ndef crop(image,tl,br,shape):\r\n\r\n    vp.debug( repr( ( tl, br ) ) )\r\n    mask \u003d np.zeros( (image.shape[0],image.shape[1]), np.uint8)\r\n    x1 \u003d min(tl[0],br[0])\r\n    y1 \u003d min(tl[1],br[1])\r\n    x2 \u003d max(tl[0],br[0])\r\n    y2 \u003d max(tl[1],br[1])\r\n    if shape \u003d\u003d 1:\r\n      cv2.rectangle(mask,(x1,y1),(x2,y2),(255,255,255),-1)\r\n    else:\r\n      cx \u003d x1 + (x2-x1) / 2.0\r\n      cy \u003d y1 + (y2-y1) / 2.0\r\n      cv2.ellipse(mask,((cx,cy),(x2-x1,y2-y1),0), (255,255,255), -1)\r\n    im_final \u003d cv2.bitwise_and(image,image,mask \u003d mask)\r\n    return { \u0027image\u0027 : im_final }\r\n    \r\ndef background(image,background,foreground):\r\n\r\n    #Add back and fore ground\r\n    selection \u003d background.ColorList + foreground.ColorList\r\n    \r\n    if len(selection)\u0026lt;1:\r\n      return\r\n\r\n    #Convert color selection to L*a*b\r\n    sel \u003d cv2.cvtColor( np.array([selection],dtype\u003d\u0027uint8\u0027), cv2.COLOR_BGR2LAB ).astype(\"float32\")[0]\r\n\r\n    #Convert image to L*a*b\r\n    src \u003d cv2.cvtColor( image, cv2.COLOR_BGR2LAB )\r\n\r\n\t  #find index of near euclidian distance to each color pixel    \r\n    weights \u003d np.ones( len(sel), dtype\u003d\u0027float\u0027 )\r\n    #weights \u003d np.array( [1.0]*len(background.ColorList)+[2.0]*len(foreground.ColorList), dtype\u003d\u0027float\u0027 )\r\n    ( results, dst ) \u003d vp2.colorClassification( src, sel.tolist(), weights )\r\n\r\n    #find the minimal\r\n    backOrForeground \u003d np.array( [0] * len(background.ColorList) + [255] * len(foreground.ColorList), dtype\u003d\u0027uint8\u0027 )\r\n    label \u003d backOrForeground[ dst ]\r\n        \r\n    return { \u0027image\u0027 : label }\r\n    \r\ndef morphology(image,operation,size):\r\n\r\n    kernel \u003d cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(size,size))  \r\n    im \u003d cv2.morphologyEx( image, operation, kernel )\r\n    return { \u0027image\u0027 : im }\r\n  \r\ndef fillHoles(image,min_filter,max_filter):\r\n    \r\n    #findContours function erase input image so clone it\r\n    clone1 \u003d np.copy(image)\r\n    clone2 \u003d np.copy(image)\r\n    contours,hierarchy \u003d cv2.findContours( clone1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\r\n\r\n    for (i,cnt) in enumerate(contours):\r\n      parent \u003d hierarchy[0,i,3]\r\n      if parent !\u003d -1 : #has parent so it is hole\r\n        area \u003d cv2.contourArea(cnt)\r\n        if area\u0026gt;min_filter and area\u0026lt;max_filter:\r\n          cv2.drawContours(clone2,[cnt],0,(255,255,255),-1)\r\n          \r\n    return { \u0027image\u0027 : clone2 }          \r\n\r\ndef standardResult(image,scale):\r\n    \r\n    if ( len(image.shape) \u0026gt; 2 ):\r\n      raise Exception(\u0027Input image must be monochrom\u0027)\r\n            \r\n    contours,hierarchy \u003d cv2.findContours( np.copy(image), cv2.cv.CV_RETR_EXTERNAL, cv2.cv.CV_CHAIN_APPROX_SIMPLE )\r\n      \r\n    if ( len(contours)\u0026lt;1 ):\r\n      return { \u0027image\u0027 : image }          \r\n    \r\n    #Merge Contours\r\n    concat_contours \u003d contours[0]\r\n    for cnt in contours[1:]:\r\n      if len(cnt)\u0026gt;3:\r\n\t      concat_contours \u003d np.concatenate( [concat_contours, cnt] )\r\n        \r\n    pb_x,pb_y,pb_w,pb_h \u003d cv2.boundingRect(concat_contours)\r\n    \r\n    rect \u003d cv2.minAreaRect( concat_contours )\r\n    (np_x,np_y),(np_w,np_h),np_teta \u003d rect\r\n    \r\n    center_x, center_y, leafarea \u003d vp2.centerOfGravity(image)\r\n    \r\n    (mec_x,mec_y),mec_radius \u003d cv2.minEnclosingCircle(concat_contours)\r\n    \r\n    ellipse \u003d ((-1,-1),(-1,-1),-1)\r\n    if len(concat_contours)\u0026gt;5:\r\n      ellipse \u003d cv2.fitEllipse(concat_contours)\r\n    (ell_x,ell_y),(ell_w,ell_h),ell_teta \u003d ellipse\r\n    \r\n    hull \u003d cv2.convexHull(concat_contours)\r\n    \r\n    #Save binary image    \r\n    if vp.is_script():\r\n      cv2.imwrite( sys.argv[2], image )\r\n    \r\n    #Results generate\r\n    results \u003d { \r\n      \u0027xscale\u0027 : scale[0],\r\n      \u0027yscale\u0027 : scale[1],\r\n      \u0027unitscale\u0027 : scale[2],\r\n      \r\n      \u0027parallelboundingbox_x\u0027 : pb_x,\r\n      \u0027parallelboundingbox_y\u0027 : pb_y,\r\n      \u0027parallelboundingbox_width\u0027 : pb_w,\r\n      \u0027parallelboundingbox_height\u0027 : pb_h,\r\n      \u0027parallelboundingbox_area\u0027 : pb_w*pb_h,\r\n      \r\n      \u0027nonparallelboundingbox_x\u0027 : np_x,\r\n      \u0027nonparallelboundingbox_y\u0027 : np_y,\r\n      \u0027nonparallelboundingbox_width\u0027 : np_w,\r\n      \u0027nonparallelboundingbox_height\u0027 : np_h,\r\n      \u0027nonparallelboundingbox_area\u0027 : np_w*np_h,\r\n      \u0027nonparallelboundingbox_teta\u0027 : np_teta,\r\n      \r\n      \u0027height\u0027 : 0,\r\n      \r\n      \u0027centerofmassx\u0027 : center_x,\r\n      \u0027centerofmassy\u0027 : center_y,\r\n      \r\n      \u0027area_color_1\u0027 : leafarea,\r\n      \u0027area_color_2\u0027 : 0,\r\n      \r\n      \u0027fitellipse_x\u0027 : ell_x,\r\n      \u0027fitellipse_y\u0027 : ell_y,\r\n      \u0027fitellipse_width\u0027 : ell_w,\r\n      \u0027fitellipse_height\u0027 : ell_h,\r\n      \u0027fitellipse_teta\u0027 : ell_teta,\r\n      \u0027fitellipse_area\u0027 : ( math.pi * ell_w * ell_h ) / 4.,\r\n      \r\n      \u0027minenclosingcircle_x\u0027 : mec_x,\r\n      \u0027minenclosingcircle_y\u0027 : mec_y,\r\n      \u0027minenclosingcircle_radius\u0027 : mec_radius,\r\n      \u0027minenclosingcircle_area\u0027 : math.pi * mec_radius * mec_radius,\r\n      \r\n      \u0027convexhull\u0027 : hull.tolist(),      \r\n      \r\n      }\r\n      \r\n    #Results\r\n    sys.stdout.write ( \u0027\\t\u0027.join([ \"%s|\" % k + str(v) for k,v in results.iteritems() ]) )      \r\n      \r\n    #Draw\r\n    im_rgb \u003d None\r\n    if not vp.is_script():\r\n      im_rgb \u003d cv2.cvtColor( image, cv2.COLOR_GRAY2BGR )\r\n    \r\n      #Center Of gravity\r\n      cog_size \u003d 2\r\n      cv2.line( im_rgb, ( int(center_x) - cog_size, int(center_y) - cog_size ), ( int(center_x) + cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n      cv2.line( im_rgb, ( int(center_x) + cog_size, int(center_y) - cog_size ), ( int(center_x) - cog_size, int(center_y) + cog_size ), (0,0,255) )\r\n    \r\n      #hori rect\r\n      cv2.rectangle(im_rgb,(pb_x,pb_y),(pb_x+pb_w,pb_y+pb_h),(255,0,0))\r\n      #rotate rect\r\n      box \u003d cv2.cv.BoxPoints(rect)\r\n      box \u003d np.int0(box)\r\n      cv2.drawContours(im_rgb,[box],0,(0,0,255))\r\n    \r\n      #Hull\r\n      hull \u003d cv2.convexHull(concat_contours)\r\n      cv2.drawContours(im_rgb,[hull],0,(0,255,0))\r\n    \r\n      #minEnclosingCircle\r\n      center \u003d (int(mec_x),int(mec_y))\r\n      radius \u003d int(mec_radius)\r\n      cv2.circle(im_rgb,center,radius,(0,255,255))\r\n      \r\n      #fitEllipse\r\n      cv2.ellipse(im_rgb,ellipse,(255,0,255))   \r\n    \r\n    return { \u0027image\u0027 : im_rgb }          \r\n\r\nvar_imread_1 \u003d imread(1)\r\nvar_crop_2 \u003d crop(var_imread_1[\u0027image\u0027],(529, 576),(1556, 1812),1)\r\nvar_background_3 \u003d background(var_crop_2[\u0027image\u0027],VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(0, 0, 0),ColorList\u003d[(255, 255, 255), (37, 84, 202), (37, 77, 157), (14, 18, 20), (133, 122, 115), (81, 91, 90), (52, 94, 127), (22, 46, 90), (107, 98, 80), (77, 104, 133), (49, 55, 52), (46, 52, 54), (42, 49, 50), (47, 50, 40), (72, 89, 107), (69, 137, 218), (170, 183, 184), (255, 255, 255), (224, 229, 232), (150, 156, 157), (138, 147, 139)]),VpTypes.ColorList(Name\u003d\u0027\u0027,Color\u003d(255, 255, 255),ColorList\u003d[(41, 104, 107), (38, 50, 43), (24, 68, 54), (59, 116, 87), (134, 144, 116), (103, 115, 97), (84, 103, 80), (79, 95, 70), (126, 126, 100), (99, 98, 72), (105, 99, 76), (105, 99, 76), (121, 112, 93), (90, 172, 152)]))\r\nvar_morphology_4 \u003d morphology(var_background_3[\u0027image\u0027],2L,2)\r\nvar_fillHoles_5 \u003d fillHoles(var_morphology_4[\u0027image\u0027],0,10000)\r\nvar_standardResult_6 \u003d standardResult(var_fillHoles_5[\u0027image\u0027],(0.01, 0.01, \u0027cm\u0027))\r\n\u003c/Code\u003e\u003c/FlowView\u003e"
}
